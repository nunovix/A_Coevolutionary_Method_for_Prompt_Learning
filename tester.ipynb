{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data quality function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set available gpu's\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_string_for_semeval_data_quality(datapoint: dict):\n",
    "\n",
    "    task_description = \"Natural Language Inference task between Clinical Trial Reports' (CTRs) Sections and a Statement made by a specialist. The Statement can be made about a single CTR or two CTRs. There are two possible relations between the statement and the CTRs: Entailment or Contradiction\"\n",
    "    primary_evidence = \"\\n\".join(datapoint['primary_evidence'])\n",
    "    statement = datapoint['statement']\n",
    "    label = datapoint['label']\n",
    "\n",
    "    semeval_text = f\"\"\"Task description: {task_description}\\n\\nPrimary Trial:\\n{primary_evidence}\\n\\n\"\"\"\n",
    "\n",
    "    if 'secondary_evidence' in datapoint.keys():\n",
    "        secondary_evidence = \"\\n\".join(datapoint['secondary_evidence'])\n",
    "        semeval_text = f\"\"\"{semeval_text}Secondary Trial:\\n{secondary_evidence}\\n\\n\"\"\"\n",
    "\n",
    "    semeval_text = f\"\"\"{semeval_text} Statement: {statement}\\n\\nRelation: {label}\"\"\"\n",
    "\n",
    "    return semeval_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_assessment_save(task):\n",
    "    # extract data acording to selected task\n",
    "    # combine the validation and the training data\n",
    "    # expect same format for all TRUE\n",
    "    # create prompt part between ### and ###, one for each task\n",
    "        # semeval\n",
    "        # contract nli\n",
    "        # mediqa sum\n",
    "        # lex sum\n",
    "    # append to common part\n",
    "    # loop through and performance the inferences\n",
    "        # in loop save the score\n",
    "    # save new variation with the scores (in the same format they were extracted from but in reverse order of the scores)\n",
    "    # so that in the implementation of extract from scored variation we just select the top k and o ordering is done there\n",
    "\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def data_quality_inference(data_quality_prompt, model, tokenizer):\n",
    "\n",
    "    encoded_inputs = tokenizer(data_quality_prompt, return_tensors=\"pt\", return_attention_mask=True, padding=True).to('cuda')\n",
    "    input_len = encoded_inputs['input_ids'][0].shape[0]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(encoded_inputs['input_ids'],\n",
    "                                attention_mask=encoded_inputs['attention_mask'], \n",
    "                                max_new_tokens=1,\n",
    "                                return_dict_in_generate=True,\n",
    "                                output_scores=True,\n",
    "                                )\n",
    "        \n",
    "\n",
    "    # Decode the generated sequence (excluding input)\n",
    "    generated_ids = output.sequences[0, encoded_inputs['input_ids'].shape[-1]:]  # Exclude the input part\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    print(f\"generated_text-->{generated_text}\")\n",
    "\n",
    "    logits = output.scores[-1]  # logits of the last token\n",
    "\n",
    "    # Calculate probabilities\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "    yes_token_id = tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "\n",
    "    # Check if the token id is valid and present\n",
    "    if yes_token_id != tokenizer.pad_token_id and yes_token_id < len(probabilities[0]):\n",
    "        yes_token_prob = probabilities[0, yes_token_id].item()\n",
    "    else:\n",
    "        yes_token_prob = 0.0\n",
    "\n",
    "    print(f\"yes_token_prob-->{yes_token_prob}\")\n",
    "        \n",
    "    return yes_token_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo_functions import load_model, extract_SemEval_data\n",
    "import json\n",
    "\n",
    "def data_quality_assessment_and_save(task: str):\n",
    "\n",
    "    base_data_quality_prompt = f\"\"\"The previous paragraph demarcated within ### and ### is a datapoint from a dataset. Your task is to determine whether this datapoint is a well-structured and informative example that would be valuable for evaluating the performance of a large-language model. An informative datapoint should be well-formatted, contain some usable knowledge of the task, and serve as a strong representation of the overall dataset.\\n\\nOPTIONS:\\n- yes\\n- no \"\"\"\n",
    "    \n",
    "    # Step 1: Determine and execute the appropriate data extraction function based on `task`\n",
    "    if task == \"SemEval\":\n",
    "        train_data = extract_SemEval_data(type = 'train')\n",
    "        validation_data = extract_SemEval_data(type = 'dev')\n",
    "        full_data = train_data + validation_data\n",
    "        full_data = full_data[:10]\n",
    "    elif task == \"task2\":\n",
    "        pass\n",
    "    elif task == \"task3\":\n",
    "        pass\n",
    "    elif task == \"task4\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Invalid task provided.\")\n",
    "    \n",
    "    # Step 2: Generate a specific string for each data point\n",
    "    for i in range(len(full_data)):\n",
    "        if task == \"SemEval\":\n",
    "            datapoint_string = generate_string_for_semeval_data_quality(full_data[i])\n",
    "        elif task == \"task2\":\n",
    "            pass\n",
    "        elif task == \"task3\":\n",
    "            pass\n",
    "        elif task == \"task4\":\n",
    "            pass\n",
    "        \n",
    "        # Combine with base_string\n",
    "        data_quality_prompt = f\"<s><|user|>\\n###\\n{datapoint_string}\\n###\\n\\n{base_data_quality_prompt}<|end|>\\n<|assistant|>\"\n",
    "        \n",
    "        # Add to data_list\n",
    "        full_data[i]['data_quality_prompt'] = data_quality_prompt\n",
    "        #processed_data.append({\"original_data\": item, \"combined_string\": combined_string, \"score\": None})\n",
    "    \n",
    "    # Step 3: Perform inferences in a loop\n",
    "\n",
    "    model, tokenizer = load_model(checkpoint = \"microsoft/Phi-3-mini-4k-instruct\", quantized = True)\n",
    "\n",
    "    for i in range(len(full_data)):\n",
    "        data_quality_score = data_quality_inference(data_quality_prompt = full_data[i][\"data_quality_prompt\"], \n",
    "                                                    model = model, \n",
    "                                                    tokenizer = tokenizer)\n",
    "        full_data[i][\"score\"] = data_quality_score\n",
    "    \n",
    "    # Step 4: Sort the processed data by the `score` in descending order\n",
    "    full_data.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    filtered_data = [{k: v for k, v in item.items() if k != 'data_quality_prompt'} for item in full_data]\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    file_name = 'DATASETS_data_quality/' + \"semeval_data_quality.json\"\n",
    "    with open(file_name, 'w') as json_file:\n",
    "        json.dump(filtered_data, json_file, indent=4)\n",
    "    \n",
    "    print(f\"Data with data quality assessment saved to {file_name}!\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used data with already retrieved examples from DATASETS/SemEval_data/train_w_retrieved.json\n",
      "Used data with already retrieved examples from DATASETS/SemEval_data/dev_w_retrieved.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi-3 selecionado\n",
      "generated_text-->no\n",
      "yes_token_prob-->1.0730951544246636e-05\n",
      "generated_text-->no\n",
      "yes_token_prob-->2.451200771247386e-06\n",
      "generated_text-->yes\n",
      "yes_token_prob-->1.1769451703003142e-05\n",
      "generated_text-->no\n",
      "yes_token_prob-->3.345698132761754e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->3.581266810215311e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->3.4976460483449046e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->5.558356406254461e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->7.388226549664978e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->8.138037628668826e-06\n",
      "generated_text-->no\n",
      "yes_token_prob-->1.031119427352678e-05\n",
      "Data with data quality assessment saved to DATASETS_data_quality/semeval_data_quality.json!\n"
     ]
    }
   ],
   "source": [
    "data_quality_assessment_and_save(task = 'SemEval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "Task description: Natural Language Inference between Clinical Trial Reports Sections and a Statement made by a specialist. The Statement can be made about one or two Clinical Trial Reports. There are two possible relations: Entailment and Contradiction \n",
      "Primary Trial:\n",
      "INTERVENTION 1: \n",
      "  Diagnostic (FLT PET)\n",
      "  Patients with early stage, ER positive primary breast cancer undergo FLT PET scan at baseline and 1-6 weeks after the start of standard endocrine treatment. The surgery follows 1-7 days after the second FLT PET scan.\n",
      "  Tracer used in the FLT PET (positron emission tomography) scanning procedure: [F18] fluorothymidine.\n",
      "  Positron Emission Tomography: Undergo FLT PET\n",
      "  Laboratory Biomarker Analysis: Correlative studies - Ki67 staining of the tumor tissue in the biopsy and surgical specimen.\n",
      "\n",
      " Secondary Trial:\n",
      "INTERVENTION 1: \n",
      "  Arm A\n",
      "  Patients receive oral capecitabine twice daily on days 1-14 and oral lapatinib ditosylate once daily on days 1-21. Courses repeat every 21 days in the absence of disease progression or unacceptable toxicity. lapatinib ditosylate: Given PO and capecitabine: Given PO\n",
      "INTERVENTION 2: \n",
      "  Arm B\n",
      "  Patients receive capecitabine and lapatinib ditosylate as in arm I. Patients also receive cixutumumab IV over 1-1½ hours on days 1, 8, and 15. Courses repeat every 21 days in the absence of disease progression or unacceptable toxicity. cixutumumab: Given IV, lapatinib ditosylate: Given PO and capecitabine: Given PO\n",
      "\n",
      " Statement:All the primary trial participants do not receive any oral capecitabine, oral lapatinib ditosylate or cixutumumab IV, in conrast all the secondary trial subjects receive these.\n",
      "\n",
      "Relation: Contradiction\n",
      " ###\n"
     ]
    }
   ],
   "source": [
    "test = generate_string_for_semeval_data_quality(full_data[0])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "Task description: Natural Language Inference between Clinical Trial Reports Sections and a Statement made by a specialist. The Statement can be made about one or two Clinical Trial Reports. There are two possible relations: Entailment and Contradiction \n",
      "Primary Trial:\n",
      "DISEASE CHARACTERISTICS:\n",
      "  Histologically or cytologically confirmed infiltrating breast cancer\n",
      "  Clinical evidence of metastatic disease\n",
      "  Measurable disease, defined as at least one measurable lesion per RECIST criteria\n",
      "  No non-measurable disease only, defined as all other lesions, including small lesions (longest diameter < 2 cm) and truly non-measurable lesions, including any of the following:\n",
      "  Bone lesions\n",
      "  Leptomeningeal disease\n",
      "  Ascites\n",
      "  Pleural/pericardial effusion\n",
      "  Inflammatory breast disease\n",
      "  Lymphangitis cutis/pulmonis\n",
      "  Abdominal masses that are not confirmed and followed by imaging techniques\n",
      "  Cystic lesions\n",
      "  Patients with HER-2/neu positive tumors, must have received prior treatment with trastuzumab (Herceptin®) or have a contraindication for trastuzumab\n",
      "  No evidence of active brain metastasis, including leptomeningeal involvement, on MRI or CT scan\n",
      "  CNS metastasis controlled by prior surgery and/or radiotherapy allowed\n",
      "  Must be asymptomatic for  2 months with no evidence of progression prior to study entry\n",
      "  Hormone receptor status not specified\n",
      "  PATIENT CHARACTERISTICS:\n",
      "  Menopausal status not specified\n",
      "  Life expectancy  12 weeks\n",
      "  ECOG performance status 0-1\n",
      "  ANC  1,500/mm³\n",
      "  Platelet count  100,000/mm³\n",
      "  Hemoglobin  9.0 g/dL\n",
      "  AST and ALT  2.5 times upper limit of normal (ULN)\n",
      "  Alkaline phosphatase  2.5 times ULN\n",
      "  Total bilirubin  1.5 times ULN\n",
      "  Creatinine  1.5 mg/dL\n",
      "  Urine protein:creatinine ratio < 1 or urinalysis < 1+ protein\n",
      "  Patients discovered to have  1+ proteinuria at baseline must demonstrate 24-hour urine protein < 1 g\n",
      "  Not pregnant or nursing\n",
      "  Negative pregnancy test\n",
      "  Fertile patients must use effective contraception during and for 30 days after completion of study therapy\n",
      "  Able to complete questionnaires alone or with assistance\n",
      "  No peripheral neuropathy > grade 1\n",
      "  No history of allergy or hypersensitivity to albumin-bound paclitaxel, paclitaxel, gemcitabine hydrochloride, bevacizumab, albumin, drug product excipients, or chemically similar agents\n",
      "  No stage III or IV invasive, non-breast malignancy within the past 5 years\n",
      "  No other active malignancy, except nonmelanoma skin cancer or carcinoma in situ of the cervix\n",
      "  Patient must not be receiving other specific treatment for a prior malignancy\n",
      "  No uncontrolled hypertension (i.e., blood pressure [BP] > 160/90 mm Hg on  2 occasions at least 5 minutes apart)\n",
      "  Patients who have recently started or adjusted antihypertensive medications are eligible providing that BP is < 140/90 mm Hg on any new regimen for  3 different observations in  14 days\n",
      "  No bleeding diathesis or uncontrolled coagulopathy\n",
      "  No hemoptysis within the past 6 months\n",
      "  No prior arterial or venous thrombosis within the past 12 months\n",
      "  No history of cerebrovascular accident\n",
      "  No history of hypertensive crisis or hypertensive encephalopathy\n",
      "  No abdominal fistula or gastrointestinal perforation within the past 6 months\n",
      "  No serious non-healing wound, ulcer, or fracture\n",
      "  No clinically significant cardiac disease, defined as any of the following:\n",
      "  Congestive heart failure\n",
      "  Symptomatic coronary artery disease\n",
      "  Unstable angina\n",
      "  Cardiac arrhythmias not well controlled with medication\n",
      "  Myocardial infarction within the past 12 months\n",
      "  No comorbid systemic illnesses or other severe concurrent disease which, in the judgment of the investigator, would make the patient inappropriate for study entry or interfere significantly with the proper assessment of safety and toxicity of the prescribed regimens\n",
      "  PRIOR CONCURRENT THERAPY:\n",
      "  See Disease Characteristics\n",
      "  No prior chemotherapy for metastatic disease\n",
      "  May have received one prior adjuvant chemotherapy regimen\n",
      "  Prior neoadjuvant chemotherapy allowed\n",
      "  More than 6 months since prior adjuvant or neoadjuvant taxane (i.e., docetaxel or paclitaxel) therapy\n",
      "  Prior hormonal therapy in either adjuvant or metastatic setting allowed\n",
      "  More than 4 weeks since prior radiotherapy (except if to a non-target lesion only, or single dose radiation for palliation)\n",
      "  Prior radiotherapy to a target lesion is allowed provided there has been clear progression of the lesion since radiotherapy was completed\n",
      "  More than 4 weeks since prior cytotoxic chemotherapeutic agent or investigational drug\n",
      "  More than 2 weeks since prior and no concurrent acetylsalicylic acid, anticoagulants, or thrombolytic agents (except for once-daily 81 mg acetylsalicylic acid)\n",
      "  More than 6 weeks since prior major surgery, chemotherapy, or immunologic therapy\n",
      "  More than 1 week since prior minor surgery (e.g., core biopsy)\n",
      "  Placement of a vascular access device within 7 days is allowed\n",
      "  More than 3 months since prior neurosurgery\n",
      "  No concurrent treatment in a different clinical study in which investigational procedures are performed or investigational therapies are administered\n",
      "  Trials related to symptom management (Cancer Control) which do not employ hormonal treatments or treatments that may block the path of the targeted agents used in this study may be allowed\n",
      "\n",
      " Statement:Patients with Platelet count over 100,000/mm¬¨‚â•, ANC <  1,700/mm¬¨‚â• and Hemoglobin between 4 to 5 grams per deciliter are eligible for the primary trial.\n",
      "\n",
      "Relation: Contradiction\n",
      " ###\n"
     ]
    }
   ],
   "source": [
    "test = generate_string_for_semeval_data_quality(full_data[1])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract_LEXSUM_data(used_retrieved_file = False)\n",
    "\n",
    "import os\n",
    "# set available gpu's\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "from evo_functions import convert_text_mistral_phi3\n",
    "\n",
    "torch.random.manual_seed(0) \n",
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",  \n",
    "    device_map=\"cuda\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ") \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\") \n",
    "\n",
    "\n",
    "sentence = \"\"\"<s><|user|>Below will be a question to a test with two possible answers: yer or no. Output only one of them\n",
    "\n",
    "Is Lisbon the capital of Portugal?\n",
    "\n",
    "OPTIONS:\n",
    "- yes\n",
    "- no<|end|>\n",
    "<|assistant|> \n",
    "\"\"\"\n",
    "\n",
    "#sentence = convert_text_mistral_phi3(sentence)\n",
    "\n",
    "encoded_inputs = tokenizer(sentence,return_tensors=\"pt\", return_attention_mask=True, padding=True).to('cuda')\n",
    "input_len = encoded_inputs['input_ids'][0].shape[0]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    output = model.generate(encoded_inputs['input_ids'],\n",
    "                            attention_mask=encoded_inputs['attention_mask'], \n",
    "                            max_new_tokens=1,\n",
    "                            return_dict_in_generate=True,\n",
    "                            output_scores=True,\n",
    "                            )\n",
    "    \n",
    "\n",
    "# Decode the generated sequence (excluding input)\n",
    "generated_ids = output.sequences[0, encoded_inputs['input_ids'].shape[-1]:]  # Exclude the input part\n",
    "generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(f\"output.keys()-->{output.keys()}\")\n",
    "logits = output.scores[-1]  # logits of the last token\n",
    "\n",
    "# Calculate probabilities\n",
    "probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "yes_token_id = tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "no_token_id = tokenizer.convert_tokens_to_ids(\"no\")\n",
    "\n",
    "\n",
    "# Check if the token id is valid and present\n",
    "if yes_token_id != tokenizer.pad_token_id and yes_token_id < len(probabilities[0]):\n",
    "    yes_token_prob = probabilities[0, yes_token_id].item()\n",
    "else:\n",
    "    yes_token_prob = 0.0\n",
    "\n",
    "# Check if the token id is valid and present\n",
    "if no_token_id != tokenizer.pad_token_id and no_token_id < len(probabilities[0]):\n",
    "    no_token_prob = probabilities[0, no_token_id].item()\n",
    "else:\n",
    "    no_token_prob = 0.0\n",
    "\n",
    "\n",
    "print(f\"Generated text: {generated_text}\")\n",
    "print(f\"Probability of 'yes': {yes_token_prob:.8f}\")\n",
    "print(f\"Probability of 'no': {no_token_prob:.8f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from evo_functions import extract_SemEval_data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
